{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaJ83sAHQPS15wQlAXgu2b"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"uciml/sms-spam-collection-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "A8KMSTmlziyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca4206a-3bf5-490c-ba61-c8fb5d7f8168"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/uciml/sms-spam-collection-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 211k/211k [00:00<00:00, 26.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/uciml/sms-spam-collection-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import *\n",
        "from sklearn.dummy import *\n",
        "from sklearn.ensemble import *\n",
        "from sklearn.neighbors import *\n",
        "from sklearn.tree import *\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.calibration import *\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.multiclass import *\n",
        "from sklearn.svm import *\n",
        "import pandas\n"
      ],
      "metadata": {
        "id": "lvct1pt8Zq8-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.dummy import *\n",
        "from sklearn.ensemble import *\n",
        "from sklearn.neighbors import *\n",
        "from sklearn.tree import *\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.calibration import *\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.multiclass import *\n",
        "from sklearn.svm import *\n",
        "import pandas\n",
        "import csv\n",
        "\n",
        "data = pandas.read_csv('spam.csv', encoding='latin-1')\n",
        "train_data = data[:4400] # 4400 items\n",
        "test_data = data[4400:] # 1172 items\n",
        "\n",
        "classifier = OneVsRestClassifier(SVC(kernel='linear'))\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# train\n",
        "vectorize_text = vectorizer.fit_transform(train_data.v2)\n",
        "classifier.fit(vectorize_text, train_data.v1)\n",
        "\n",
        "# score\n",
        "vectorize_text = vectorizer.transform(test_data.v2)\n",
        "score = classifier.score(vectorize_text, test_data.v1)\n",
        "print(score) # 98,8\n",
        "\n",
        "\n",
        "csv_arr = []\n",
        "for index, row in test_data.iterrows():\n",
        "    answer = row[0]\n",
        "    text = row[1]\n",
        "    vectorize_text = vectorizer.transform([text])\n",
        "    predict = classifier.predict(vectorize_text)[0]\n",
        "    if predict == answer:\n",
        "        result = 'right'\n",
        "    else:\n",
        "        result = 'wrong'\n",
        "    csv_arr.append([len(csv_arr), text, answer, predict, result])\n",
        "\n",
        "\n",
        "# write csv\n",
        "with open('test_score.csv', 'w', newline='') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=';',\n",
        "            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    spamwriter.writerow(['#', 'text', 'answer', 'predict', result])\n",
        "\n",
        "    for row in csv_arr:\n",
        "        spamwriter.writerow(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwDN-iNfcjcc",
        "outputId": "5f539790-8ac4-433f-e192-c7c5b3315ec8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9880546075085325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-268ec5b35b07>:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  answer = row[0]\n",
            "<ipython-input-7-268ec5b35b07>:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  text = row[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from flask import Flask, render_template, request, redirect, url_for, jsonify\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import *\n",
        "from sklearn.svm import *\n",
        "import pandas\n",
        "\n",
        "app = Flask(__name__)\n",
        "global Classifier\n",
        "global Vectorizer\n",
        "\n",
        "# load data\n",
        "data = pandas.read_csv('spam.csv', encoding='latin-1')\n",
        "train_data = data[:4400] # 4400 items\n",
        "test_data = data[4400:] # 1172 items\n",
        "\n",
        "# train model\n",
        "Classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
        "Vectorizer = TfidfVectorizer()\n",
        "vectorize_text = Vectorizer.fit_transform(train_data.v2)\n",
        "Classifier.fit(vectorize_text, train_data.v1)\n",
        "\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def index():\n",
        "    message = request.args.get('message', '')\n",
        "    error = ''\n",
        "    predict_proba = ''\n",
        "    predict = ''\n",
        "\n",
        "    global Classifier\n",
        "    global Vectorizer\n",
        "    try:\n",
        "        if len(message) > 0:\n",
        "          vectorize_message = Vectorizer.transform([message])\n",
        "          predict = Classifier.predict(vectorize_message)[0]\n",
        "          predict_proba = Classifier.predict_proba(vectorize_message).tolist()\n",
        "    except BaseException as inst:\n",
        "        error = str(type(inst).__name__) + ' ' + str(inst)\n",
        "    return jsonify(\n",
        "              message=message, predict_proba=predict_proba,\n",
        "              predict=predict, error=error)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    port = int(os.environ.get('PORT', 5000))\n",
        "    app.run(host='0.0.0.0', port=port, debug=True, use_reloader=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olmu-n3_1Zia",
        "outputId": "252a01eb-c342-44f9-8584-daeb68d7b653"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}